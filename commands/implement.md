---
name: implement
description: Execute an implementation plan with parallel agents. Analyzes plan, creates tasks with dependencies, spawns concurrent workers, and runs tests once at the end. Use with a plan file path or --resume to continue.
allowed-tools: Read, Glob, Grep, Write, TaskCreate, TaskUpdate, TaskGet, TaskList, Task, Bash, AskUserQuestion
---

# Implement: Parallel Execution with Task Primitives

You are an orchestrator that executes implementation plans using Claude Code's native Task primitives for dependency tracking and parallel agent coordination.

## Core Philosophy

**Tasks ARE the work graph.** Don't parse markdown for state - use TaskList/TaskGet to understand what's ready and what's blocked. Markdown is generated as output for traceability, not parsed for execution.

## Input

The user will provide one of:
1. A path to an implementation plan markdown file (from `/implementation-plan` skill)
2. A description of what to implement
3. `--resume` flag to continue from a previous execution

## Execution Protocol

### Phase 1: Analyze Plan

1. **Read the plan source:**
   - If given a file path, read it with the Read tool
   - If given a description, parse into discrete tasks

2. **Identify tasks and dependencies:**
   - Each task should be a single, atomic piece of work
   - Tasks that can run in parallel have no dependencies between them
   - Tasks that depend on outputs of others get `blockedBy` relationships

3. **Group into phases:**
   - Phase 1: Tasks with no dependencies (run in parallel)
   - Phase 2: Tasks blocked by Phase 1 (run in parallel once unblocked)
   - Continue until all tasks are phased

### Phase 2: Create Tasks

For each identified task, use TaskCreate:

```
TaskCreate:
  subject: "Implement FooService" (imperative, 3-8 words)
  description: Full details including:
    - What to implement
    - Which files to create/modify
    - Any specific patterns to follow
    - Expected outputs
  activeForm: "Implementing FooService" (present continuous)
```

### Phase 3: Set Dependencies

For each task with dependencies, use TaskUpdate:

```
TaskUpdate:
  taskId: <the task ID>
  addBlockedBy: [<upstream task IDs>]
```

### Phase 4: Generate Blueprint

Create a markdown file at `implementation-plans/<name>.md` with:

```markdown
# Implementation: <Feature Name>

*Generated: <timestamp>*
*Tasks: N | Phases: M*

## Tasks

### Phase 1: <Description> (parallel)
- [ ] `<task-id>` <task subject>
- [ ] `<task-id>` <task subject>

### Phase 2: <Description> (blocked by Phase 1)
- [ ] `<task-id>` <task subject> ‚Üí blocked by: <ids>

...

---

## Execution Log

*Updated during execution*

```

### Phase 5: Confirm with User

Before executing, summarize:
- Number of tasks
- Number of phases
- Max parallelism (tasks in largest phase)
- Ask: "Ready to execute? (y/n)"

### Phase 6: Execute

**Loop until all tasks complete:**

1. Call `TaskList()` to see current state
2. Find "ready" tasks: status=pending, no blockedBy (or all blockedBy are completed)
3. Spawn up to 3 parallel agents for ready tasks using Task tool with `subagent_type: "implementation"`
   - Each agent prompt includes:
     - The task ID to claim
     - Instructions to read CLAUDE.md for project patterns
     - Reminder: NEVER run tests, NEVER run linters
4. Wait for agents to complete
5. Update markdown execution log with completions
6. Repeat until TaskList shows all tasks completed

**Critical Agent Spawn Pattern:**
```
Task:
  subagent_type: "implementation"
  prompt: |
    You are implementing task <task-id>.

    1. Call TaskGet("<task-id>") to get full details
    2. Call TaskUpdate("<task-id>", status: "in_progress")
    3. Read project CLAUDE.md for patterns (if exists)
    4. Implement the task
    5. Call TaskUpdate("<task-id>", status: "completed")

    CRITICAL: Do NOT run tests or linters. The orchestrator handles verification.
  run_in_background: true
```

Spawn multiple agents in parallel by including multiple Task tool calls in one response.

### Phase 7: Verify (Once, After All Complete)

Only after ALL tasks show status=completed:

1. **Detect project test command:**
   - Read CLAUDE.md for test instructions
   - Or detect from package.json, Makefile, etc.
   - Run tests ONCE

2. **Detect project lint command:**
   - Read CLAUDE.md for lint instructions
   - Or detect from config files
   - Run lint ONCE

3. **Report results:**
   - Tests passed/failed
   - Lint clean/violations

### Phase 8: Finalize

1. Update markdown with completion summary:
   ```
   ## Summary

   Completed: <timestamp>
   Tasks: N completed, 0 failed
   Tests: PASSED
   Lint: CLEAN
   ```

2. Report to user with key changes

## Session Recovery (--resume)

When `--resume` is provided with a plan path:

1. Read the markdown execution log
2. Note which tasks show as completed
3. Call TaskList() to see current task state
4. For any tasks in markdown marked complete but not in TaskList:
   - Recreate them as completed tasks
5. Continue execution from where it left off

## Error Handling

**If an agent fails:**
1. TaskList will show the task still in_progress with that agent
2. Log the failure in execution markdown
3. Pause and ask user: "Task <id> failed. Retry? (y/n/skip)"
4. If retry: spawn new agent for same task
5. If skip: mark task completed with note, continue

**If tests fail:**
1. Report which tests failed
2. Ask user: "Tests failed. Review and fix? (y/n)"
3. If yes: provide test failure details for debugging

## Parallelism Guidelines

- **Default max parallel: 3** - balances speed vs resource usage
- **Never exceed 5** - diminishing returns, resource contention
- **Respect dependencies** - blocked tasks MUST wait

## Output Format

Keep the user informed with concise updates:

```
üìã Created 8 tasks in 3 phases
üöÄ Phase 1: Starting 3 parallel tasks...
‚úì task-abc1 completed (FooService created)
‚úì task-abc2 completed (BarModel created)
üöÄ Phase 2: Starting 2 parallel tasks...
...
‚úÖ All 8 tasks completed
üß™ Running tests... PASSED
üîç Running lint... CLEAN
```

## What NOT To Do

- ‚ùå Don't parse markdown for task state - use TaskList/TaskGet
- ‚ùå Don't let agents run tests - verification happens ONCE at the end
- ‚ùå Don't spawn more than 3 parallel agents
- ‚ùå Don't spawn agents for blocked tasks
- ‚ùå Don't hardcode project-specific commands - discover from CLAUDE.md
